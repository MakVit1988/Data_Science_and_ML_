{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stepik ML contest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы начинаем соревнование! \n",
    "\n",
    "Задача нам уже знакома - нужно предсказать, сможет ли пользователь успешно закончить онлайн курс Анализ данных в R.\n",
    "Мы будем считать, что пользователь успешно закончил курс, если он правильно решил больше 40 практических заданий.\n",
    "\n",
    "В данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission_data_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "events_data_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "хранится информация о решениях и действиях для 6184 студентов за первые два дня прохождения курса. Это 6184 студентов, которые проходили курс в период с мая 2018 по январь 2019.   \n",
    "\n",
    "Используя данные о первых двух днях активности на курсе вам нужно предсказать, наберет ли пользователь более 40 баллов на курсе или нет.\n",
    "\n",
    "В этих данных, вам доступны только первые дня активности студентов для того, чтобы сделать предсказание. На самом деле, используя эти данные, вы уже можете сделать прогноз. Например, если пользователь за первые два дня набрал 40 баллов, скорее всего он наберет более 40 баллов в дальнейшем. Чтобы подкрепить такие гипотезы, вы можете использовать данные, на которые мы исследовали в первых двух модулях курса, где для всех пользователей представлены все данные об их активности на курсе. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data_train = pd.read_csv('event_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_data_train = pd.read_csv('submissions_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_filter(data : object, days = 2) -> object:\n",
    "    \n",
    "    \"\"\"  Функция создает датафрэйм с данными по действиям юзера за первых 2 дня его прибывания на Stepik\"\"\"\n",
    "    \n",
    "    # преобразовываем days в секунды\n",
    "    learning_time_threshold = days * 24 * 60 * 60\n",
    "    \n",
    "    # группируем все данные по user_id и определяем у каждого уникального user_id минимальный timestamp \n",
    "    # (первый день на Stepik) и записываем данные в переменную\n",
    "    min_user_time_submissions = data.groupby('user_id')\\\n",
    "                            .agg({'timestamp': 'min'}) \\\n",
    "                            .rename(columns={'timestamp': 'min_timestamp'}) \\\n",
    "                            .reset_index()\n",
    "    \n",
    "    # добавляем данные о первом дне в новый датафрэйм\n",
    "    data_two_days = data.merge(min_user_time_submissions, on='user_id', how='outer')\n",
    "    \n",
    "    # отбираем все даннные, у которых timestamp <= min_timestamp + 2 дня\n",
    "    data_two_days = data_two_days.query(\"timestamp <= min_timestamp + @learning_time_threshold\")\n",
    "    \n",
    "    # удаляем столбец min_timestamp\n",
    "    data_two_days = data_two_days.drop(['min_timestamp'], axis=1)\n",
    "    \n",
    "    # проверка\n",
    "    assert min_user_time_submissions.user_id.nunique() == data_two_days.user_id.nunique(), 'Кол-во уникальных рользователей не совпадает'\n",
    "    \n",
    "    return data_two_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_action_submissions(event_data_two_days: object, submissions_data_two_days: object)->object:\n",
    "    \n",
    "    \"\"\" Создает датафрэйм с основными фичами\"\"\"\n",
    "    \n",
    "    # Сводная таблица по двум дням для event_data\n",
    "    user_event_data_two_days = event_data_two_days.pivot_table(index = 'user_id', \n",
    "                                                                       columns='action', \n",
    "                                                                       values = 'step_id', \n",
    "                                                                       aggfunc = 'count', \n",
    "                                                                       fill_value = 0) \\\n",
    "                                                                       .reset_index()\n",
    "    \n",
    "    \n",
    "    # Сводная таблица по двум дням для submissions_data\n",
    "    user_submissions_data_two_days = submissions_data_two_days.pivot_table(index = 'user_id',\n",
    "                                                                                   columns='submission_status',\n",
    "                                                                                   values = 'step_id',\n",
    "                                                                                   aggfunc = 'count',\n",
    "                                                                                   fill_value = 0).reset_index()\n",
    "    \n",
    "    #  Соединяем два дата фрэйма                                                                             \n",
    "    user_data = pd.merge(user_submissions_data_two_days, user_event_data_two_days, on = 'user_id', how = 'outer').fillna(0)\n",
    "    \n",
    "    # Проверка\n",
    "    assert user_data.user_id.nunique() == event_data_two_days.user_id.nunique(), \\\n",
    "                       'Не совпадает кол-во user_id в event_data_two_days и user_event_data_two_days'\n",
    "   \n",
    "    return user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_attempts(submissions_data_two_days: object) -> object:\n",
    "    \n",
    "    \"\"\" Функция подсчитывает кол-во всех попыток usera\"\"\"\n",
    "    \n",
    "    # Считаем кол-во попыток для  user_id\n",
    "    count_attempts = submissions_data_two_days.groupby('user_id').agg({\"step_id\":\"count\"})\\\n",
    "                                                              .rename(columns={\"step_id\": \"count_attempts\"}).reset_index()\n",
    "    \n",
    "    # Проверка\n",
    "    assert count_attempts.user_id.nunique() == submissions_data_two_days.user_id.nunique(), \\\n",
    "                                'Не совпадает кол-во user_id в submissions_data_two_days и count_attempts'\n",
    "    \n",
    "    return count_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_attempts(submissions_data_two_days: object) -> object:\n",
    "    \n",
    "    \"\"\" Функция подсчитывает кол-во всех УНИКАЛЬНЫХ попыток usera\"\"\"\n",
    "    \n",
    "    # Считаем кол-во уникальных  попыток для  user_id\n",
    "    count_unique_attempts = submissions_data_two_days.groupby('user_id').step_id.nunique().to_frame().reset_index() \\\n",
    "                                       .rename(columns={'step_id': 'count_unique_attempts'})\n",
    "    \n",
    "    # Проверка\n",
    "    assert count_unique_attempts.user_id.nunique() == submissions_data_two_days.user_id.nunique(), \\\n",
    "                                'Не совпадает кол-во user_id в submissions_data_two_days и count_unique_attempts'\n",
    "    \n",
    "    return count_unique_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def users_count_correct(submissions_data_train : object, raiting = 40) -> object:\n",
    "    \n",
    "    \"\"\" Создает переменную, которую будем предсказывать\"\"\"\n",
    "    \n",
    "    # Считаем кол-во правильно решенных задач\n",
    "    users_count_correct = submissions_data_train[submissions_data_train.submission_status == 'correct'] \\\n",
    "                .groupby('user_id').agg({'step_id': 'count'}) \\\n",
    "                .reset_index().rename(columns={'step_id': 'corrects'})\n",
    "    \n",
    "    # Проверяем количесвто правильно решенных задач, если больше raiting, то True, иначе False. Добавляем колонку с данными\n",
    "    users_count_correct['passed_course'] = (users_count_correct.corrects >= raiting).astype('int')\n",
    "    \n",
    "    # удаляем колонку corrects\n",
    "    users_count_correct = users_count_correct.drop(['corrects'], axis=1)\n",
    "       \n",
    "    return users_count_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_df_train(event_data_train: object, submissions_data_train: object, days = 2) -> object:\n",
    "    \n",
    "    # Определяем дейсвтия и события user_id за два дня\n",
    "    event_data_train_two_days = time_filter(event_data_train, days)\n",
    "    submissions_data_train_two_days = time_filter(submissions_data_train, days)\n",
    "    \n",
    "    # Создаем датафрэйм с основными фичами\n",
    "    df_train = count_action_submissions(event_data_train_two_days, submissions_data_train_two_days)\n",
    "    \n",
    "    # Подсчитывает кол-во всех попыток usera\n",
    "    attempts = count_attempts(submissions_data_train_two_days)\n",
    "    \n",
    "    # Подсчитывает кол-во всех УНИКАЛЬНЫХ попыток usera\n",
    "    unique_attempts = count_unique_attempts(submissions_data_train_two_days)\n",
    "    \n",
    "    # Создаем переменную, которую будем предсказывать\n",
    "    count_correct = users_count_correct(submissions_data_train)\n",
    "    \n",
    "    # Соединяем все полученные данные\n",
    "    df_train = df_train.merge(attempts, on = 'user_id', how = 'outer')\n",
    "    df_train = df_train.merge(unique_attempts, on = 'user_id', how = 'outer')\n",
    "    df_train = df_train.merge(count_correct, on = 'user_id', how = 'outer').fillna(0)\n",
    "    \n",
    "\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_df_test(event_data_test: object, submissions_data_test: object, days = 2) -> object:\n",
    "    \n",
    "    # Определяем дейсвтия и события user_id за два дня\n",
    "    event_event_data_test = time_filter(event_data_test, days)\n",
    "    submissions_submissions_data_test = time_filter(submissions_data_test, days)\n",
    "    \n",
    "    # Создаем датафрэйм с основными фичами\n",
    "    df_test = count_action_submissions(event_data_test, submissions_data_test)\n",
    "    \n",
    "    # Подсчитывает кол-во всех попыток usera\n",
    "    attempts = count_attempts(submissions_data_test)\n",
    "    \n",
    "    # Подсчитывает кол-во всех УНИКАЛЬНЫХ попыток usera\n",
    "    unique_attempts = count_unique_attempts(submissions_data_test)\n",
    "    \n",
    "    # Создаем переменную, которую будем предсказывать\n",
    "    #count_correct = users_count_correct(submissions_data_train)\n",
    "    \n",
    "    # Соединяем все полученные данные\n",
    "    df_test = df_test.merge(attempts, on = 'user_id', how = 'outer')\n",
    "    df_test = df_test.merge(unique_attempts, on = 'user_id', how = 'outer').fillna(0)\n",
    "    #df_test = df_test.merge(count_correct, on = 'user_id', how = 'outer').fillna(0)\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data_train = pd.read_csv('event_data_train.csv')\n",
    "submissions_data_train = pd.read_csv('submissions_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = creat_df_train(event_data_train, submissions_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_train['passed_course'].map(int)\n",
    "X_data_train = data_train.drop(['passed_course'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "      <th>discovered</th>\n",
       "      <th>passed</th>\n",
       "      <th>started_attempt</th>\n",
       "      <th>viewed</th>\n",
       "      <th>count_attempts</th>\n",
       "      <th>count_unique_attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>109</td>\n",
       "      <td>84</td>\n",
       "      <td>37</td>\n",
       "      <td>154</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19229</th>\n",
       "      <td>26773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19230</th>\n",
       "      <td>26774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19231</th>\n",
       "      <td>26788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19232</th>\n",
       "      <td>26789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19233</th>\n",
       "      <td>26793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19234 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  correct  wrong  discovered  passed  started_attempt  viewed  \\\n",
       "0            2      2.0    0.0           9       9                2       9   \n",
       "1            3      4.0    4.0          15      15                4      20   \n",
       "2            5      2.0    2.0           1       1                0       1   \n",
       "3            8      9.0   21.0         109      84               37     154   \n",
       "4           14      0.0    1.0           4       3                1       9   \n",
       "...        ...      ...    ...         ...     ...              ...     ...   \n",
       "19229    26773      0.0    0.0           1       1                0       1   \n",
       "19230    26774      0.0    0.0           1       1                0       1   \n",
       "19231    26788      0.0    0.0           1       1                0       1   \n",
       "19232    26789      0.0    0.0           2       2                0       2   \n",
       "19233    26793      0.0    0.0           1       0                1       1   \n",
       "\n",
       "       count_attempts  count_unique_attempts  \n",
       "0                 2.0                    2.0  \n",
       "1                 8.0                    4.0  \n",
       "2                 4.0                    2.0  \n",
       "3                30.0                   11.0  \n",
       "4                 1.0                    1.0  \n",
       "...               ...                    ...  \n",
       "19229             0.0                    0.0  \n",
       "19230             0.0                    0.0  \n",
       "19231             0.0                    0.0  \n",
       "19232             0.0                    0.0  \n",
       "19233             0.0                    0.0  \n",
       "\n",
       "[19234 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие параметры: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__n_estimators': 29}\n",
      "Правильность на тестовом наборе: 0.90\n",
      "0.8872076426280012\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data_train, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "param_grid = {'randomforestclassifier__n_estimators': range(20, 51, 3), \n",
    "                  'randomforestclassifier__max_depth': range(5, 14)}\n",
    "    \n",
    "pipe = make_pipeline(RandomForestClassifier())\n",
    "pipe.fit(X_train, y_train)\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Наилучшие параметры: {grid.best_params_}\")\n",
    "    \n",
    "ypred_prob = grid.predict_proba(X_test)\n",
    "    \n",
    "roc_score = roc_auc_score(y_test, ypred_prob[:, 1])\n",
    "score = grid.score(X_test, y_test)\n",
    "print(f\"Правильность на тестовом наборе: {score:.2f}\")\n",
    "print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data_test = pd.read_csv('https://stepik.org/media/attachments/course/4852/submission_data_test.csv')\n",
    "events_data_test = pd.read_csv('https://stepik.org/media/attachments/course/4852/events_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = creat_df_test(events_data_test, submission_data_test).fillna(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на валид наборе: 0.900\n",
      "Roc_auc_score на валид наборе: 0.88460\n",
      "Результы записанны в файл my_predict_0.88460.csv\n"
     ]
    }
   ],
   "source": [
    "test_data = df_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_train, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "pipe = make_pipeline(RandomForestClassifier(max_depth=7, n_estimators=40,  random_state=42))\n",
    "pipe.fit(X_train, y_train)\n",
    "    \n",
    "ypred_prob = pipe.predict_proba(X_test)\n",
    "    \n",
    "roc_score = roc_auc_score(y_test, ypred_prob[:, 1])\n",
    "score = pipe.score(X_test, y_test)\n",
    "print(f\"Правильность на валид наборе: {score:.3f}\")\n",
    "print(f\"Roc_auc_score на валид наборе: {roc_score:.5f}\")\n",
    "    \n",
    "ypred_prob_final = pipe.predict_proba(test_data)\n",
    "result = test_data['user_id'].to_frame()\n",
    "result['is_gone'] = ypred_prob_final[:, 1]\n",
    "result[['user_id', 'is_gone']].to_csv(f'my_predict_{roc_score:.5f}.csv', index=False)\n",
    "print(f'Результы записанны в файл my_predict_{roc_score:.5f}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
